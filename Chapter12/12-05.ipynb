{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12-05\n",
    "## Pythonと機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習による数値の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 予測に利用するデータを作る\n",
    "import numpy as np\n",
    "\n",
    "#乱数のシードを設定\n",
    "np.random.seed(9)\n",
    "# 0から1まで100個の数値を生成，乱数要素を混ぜる前のx\n",
    "x_orig = np.linspace(0, 1, 100)\n",
    "\n",
    "def f(x):\n",
    "    # xに対応するsinを返す関数\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "# 0から1まで100個のばらけたサンプルデータ(x)を生成\n",
    "x = np.random.uniform(0, 1, size=100)[:, np.newaxis]\n",
    "# xに対応するsinに乱数値を足してサンプルデータ(y)を生成\n",
    "y = f(x)+np.random.normal(scale=0.3, size=100)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データをグラフに描く\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# 学習用データとテスト用データに分ける\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8)\n",
    "\n",
    "# 元のsinとサンプルデータをplot\n",
    "plt.plot(x_orig, f(x_orig), ls=':')\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.xlim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 最小二乗法の多項式近似を使ってデータを学習する\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 2x2のグラフを描く準備をする\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5))\n",
    "\n",
    "# 次数0, 1, 3, 9について学習した結果を表示\n",
    "for ax, deg in zip(axs.ravel(), [0, 1, 3, 9]):\n",
    "    # パイプラインを作る\n",
    "    e = make_pipeline(PolynomialFeatures(deg), LinearRegression())\n",
    "    # 学習セットで学習をする\n",
    "    e.fit(x_train, y_train)\n",
    "    # 元のxを与えて予測\n",
    "    px = e.predict(x_orig[:, np.newaxis])\n",
    "    # 予測結果のグラフとテストデータの点を描画\n",
    "    ax.scatter(x_train, y_train)\n",
    "    ax.plot(x_orig, px)\n",
    "    ax.set(xlim=(0, 1), ylim=(-2, 2),\n",
    "           ylabel='y', xlabel='x',\n",
    "           title='degree={}'.format(deg))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# テストデータを使って過学習の様子をグラフ化する\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 実データとの誤差を保存するarray\n",
    "train_error = np.empty(10)\n",
    "test_error = np.empty(10)\n",
    "# 次数0から9について調べる\n",
    "for deg in range(10):\n",
    "    # モデルを作る\n",
    "    e = make_pipeline(PolynomialFeatures(deg), LinearRegression())\n",
    "    e.fit(x_train, y_train)\n",
    "    # テストデータを使って，予測値と実際の値の誤差を調べる\n",
    "    train_error[deg] = mean_squared_error(y_train, e.predict(x_train))\n",
    "    test_error[deg] = mean_squared_error(y_test, e.predict(x_test))\n",
    "\n",
    "# グラフを描く\n",
    "plt.plot(np.arange(10), train_error, ls=':', label='train')\n",
    "plt.plot(np.arange(10), test_error, ls='-', label='test')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 名前から性別を判定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データを読み込み整形する\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "np.random.seed(9)\n",
    "# 男女のタグ付きひらがなの名前データを読み込む\n",
    "txtbody = open('names.txt', encoding='utf-8')\n",
    "# NumPyのarrayに変換\n",
    "jnames = np.array([x.split() for x in txtbody], dtype='U12')\n",
    "# 名前と性別に分割\n",
    "names_train, gender_train, = jnames[:, 1], jnames[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ひらがなの読みを2文字ごとに分割する関数を作る\n",
    "def split_in_2words(name):\n",
    "    # 名前を2文字ごとに分割する関数\n",
    "    return [name[i:i+2] for i in range(len(name)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 関数を呼び出してみる\n",
    "split_in_2words(\"とものり\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習データを作ってベクトル化の前段階となるデータを作る\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_t = CountVectorizer(analyzer=split_in_2words).fit(names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = 'かんかん'\n",
    "b1 = bow_t.transform([name])\n",
    "print(b1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 出力データから文字列を逆引きする\n",
    "# (注)直前の出力セルに表示されたIDに置き換えてください\n",
    "print(bow_t.get_feature_names()[283])\n",
    "print(bow_t.get_feature_names()[1898])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 学習データを使って文字列の出現数を数える\n",
    "names_bow = bow_t.transform(names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDFでデータの重み付けと正規化を行う\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_t = TfidfTransformer().fit(names_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfidf_tでどのような変換が行われるか確認する\n",
    "tfidf1 = tfidf_t.transform(b1)\n",
    "print(tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ナイーブベイズの多項モデルを使った学習器を作る\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# 文字列の重み付けと正規化を行う\n",
    "names_tfidf = tfidf_t.transform(names_bow)\n",
    "# 学習を実行\n",
    "namegender_detector = MultinomialNB().fit(names_tfidf, gender_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 「かんかん」という名前の性別を予測する\n",
    "print(namegender_detector.predict(tfidf1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文字列を与えて性別を予測する関数を定義\n",
    "def predict_gender(name):\n",
    "    # 性別を予測する\n",
    "    bow = bow_t.transform([name])\n",
    "    n_tfidf = tfidf_t.transform(bow)\n",
    "    return namegender_detector.predict(n_tfidf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(predict_gender(\"のんな\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データを学習データとテストデータに分割\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=split_in_2words)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# パイプラインを使って学習とテストを行う\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "scores = cross_val_score(pipeline,  # steps to convert raw messages into models\n",
    "                         names_train,  # training data\n",
    "                         gender_train,  # training labels\n",
    "                         cv=10,  # split data randomly into 10 parts: 9 for training, 1 for scoring\n",
    "                         scoring='accuracy',  # which scoring metric?\n",
    "                         n_jobs=-1,  # -1 = use all cores = faster\n",
    "                         )\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
